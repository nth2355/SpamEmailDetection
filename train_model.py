import pandas as pd
from sklearn.model_selection import train_test_split
from nltk.corpus import stopwords
import re
from sklearn.metrics import (
    accuracy_score, classification_report, f1_score, precision_score, recall_score, confusion_matrix
)
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
import os
import pickle




DATA_PATH = 'data/spam.csv'
MODEL_PATH = 'models/best_spam_detector.pkl'
NLTK_STOPWORDS = stopwords.words('english')


def clean_text(text):
    text = str(text).lower() 
    
    text = re.sub(r'[^a-z0-9\s]', '', text)
    
    tokens = text.split()
    tokens = [word for word in tokens if word not in NLTK_STOPWORDS and word.isalpha()]
    return " ".join(tokens)


def evaluate_model(y_true, y_pred, model_name):
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred, average='binary')
    rec = recall_score(y_true, y_pred, average='binary')
    f1 = f1_score(y_true, y_pred, average='binary')
    cm = confusion_matrix(y_true, y_pred)
    
    print(f"\n--- K·∫øt qu·∫£ ƒê√°nh gi√°: {model_name} ---")
    print(f"Accuracy: {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall: {rec:.4f}")
    print(f"F1-Score: {f1:.4f}")
    print("\nConfusion Matrix:\n", cm)
    
    # Tr·ª±c quan h√≥a Confusion Matrix
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['HAM (0)', 'SPAM (1)'], 
                yticklabels=['HAM (0)', 'SPAM (1)'])
    plt.title(f'Confusion Matrix for {model_name}')
    plt.ylabel('Actual Label')
    plt.xlabel('Predicted Label')
    plt.show()

    return {'model': model_name, 'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1}


def train_and_compare_traditional():
    print("--- B·∫ÆT ƒê·∫¶U CH∆Ø∆†NG TR√åNH ---")
    
    # 1. T·∫£i d·ªØ li·ªáu
    try:
            df = pd.read_csv(DATA_PATH) 
  
            if 'label' not in df.columns or 'text' not in df.columns:
                raise ValueError("File CSV ph·∫£i c√≥ c·ªôt 'label' v√† 'text'.")

            print(f"ƒê√£ t·∫£i {len(df)} m·∫´u d·ªØ li·ªáu. Ki·ªÉm tra NA...") 
        
    except FileNotFoundError:
            print(f"L·ªñI QUAN TR·ªåNG: KH√îNG T√åM TH·∫§Y FILE D·ªÆ LI·ªÜU T·∫†I {DATA_PATH}.")
            return
    except Exception as e:
            print(f"L·ªñI KH√ÅC KHI T·∫¢I D·ªÆ LI·ªÜU: {e}")
            return
    
    #2. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
    print(f"T·ªïng s·ªë m·∫´u ban ƒë·∫ßu: {len(df)}")
    #Lo·∫°i b·ªè c√°c h√†ng c√≥ gi√° tr·ªã thi·∫øu trong c·ªôt 'text' ho·∫∑c 'label'
    df.dropna(subset=['text', 'label'], inplace=True)
    
    df['label'] = df['label'].astype(int)
    
    df['cleaned_text'] = df['text'].apply(clean_text)
    
    print(f"T·ªïng s·ªë m·∫´u sau khi lo·∫°i b·ªè NA: {len(df)}")
    print(f"S·ªë m·∫´u label 1 (SPAM): {df['label'].sum()}")
    print(f"S·ªë m·∫´u label 0 (HAM): {len(df) - df['label'].sum()}")
    
    
    #3. Ph√¢n chia t·∫≠p d·ªØ li·ªáu
    X = df['cleaned_text']
    y = df['label']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    #4. Hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh
    
    tfidf = TfidfVectorizer(max_features=5000)
    
    pipelines = {
        'Naive Bayes (NB)': Pipeline([('tfidf', tfidf), ('nb', MultinomialNB())]),
        'Logistic Regression (LR)': Pipeline([('tfidf', tfidf), ('lr', LogisticRegression(max_iter=200))])
    }
    
    results = []
    
    for name, pipeline in pipelines.items():
            print(f"ƒêang hu·∫•n luy·ªán: {name}...")
            pipeline.fit(X_train, y_train)
            y_pred = pipeline.predict(X_test)
            results.append(evaluate_model(y_test, y_pred, name))
            
    #5. L∆∞u m√¥ h√¨nh t·ªët nh·∫•t(d·ª±a tr√™n F1-Score)
    best_model = max(results, key=lambda x: x['f1'])
    best_pipeline = pipelines[best_model['model']]
    
    print("\n" + "=" * 50)
    print(f"üèÜ M√î H√åNH T·ªêT NH·∫§T TRUY·ªÄN TH·ªêNG: {best_model['model']}")
    print(f"V·ªõi F1-Score: {best_model['f1']:.4f}")
    print("=" * 50)
    
    # 6. L∆∞u M√¥ h√¨nh T·ªët nh·∫•t
    os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
    with open(MODEL_PATH, 'wb') as file:
        pickle.dump(best_pipeline, file)
    print(f"\n M√¥ h√¨nh t·ªët nh·∫•t ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {MODEL_PATH}")
    
    return results
if __name__ == "__main__":
    traditional_results = train_and_compare_traditional()